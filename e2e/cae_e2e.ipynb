{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baab600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from torch.autograd import grad\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import average_precision_score\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ef38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv('./data/e2e_cleaned_dusek_et_al_2019/train-fixed.no-ol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54334843",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pandas.read_csv('./data/e2e_cleaned_dusek_et_al_2019/devel-fixed.no-ol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94614b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the examples that contained semantic errors according to Dusek et al. 2019\n",
    "bad_rows = []\n",
    "for i, row in dev_data.iterrows():\n",
    "    if row['fixed']==1:\n",
    "        bad_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = list(range(len(bad_rows)))\n",
    "random.Random(21).shuffle(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting 5 error examples\n",
    "selected = [inds[0], inds[1], inds[3], inds[7], inds[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bd2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mrs = [bad_rows[i].orig_mr for i in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112edf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_refs = [bad_rows[i].ref for i in selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually fix the erroneous references with minimal edits\n",
    "fixed_refs = [\n",
    "    \"Aromi's a coffee shop with a 3 out of 5 rating down at riverside. It has Chinese food and allows kids on the premises.\",\n",
    "    \"The Punter is an adult English coffee shop near Café Sicilia with a price range of £20-25 and a high customer rating.\",\n",
    "    \"There is a high-priced English coffee shop in the riverside area.  It is called Fitzbillies and it is family friendly, but it does have a 1 out of 5 rating.\",\n",
    "    \"Browns Cambridge is a family-friendly coffee shop with low customer rating. It serves Chinese food. They are located in Riverside near the Crowne Plaza Hotel.\",\n",
    "    \"Taste of Cambridge is a family-friendly coffee shop providing Chinese food It is located in the city centre. It is near Crowne Plaza Hotel.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd496a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = [{'document':x.orig_mr, 'summary':x.ref} for _,x in train_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f85a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_examples = [{'document':x.orig_mr, 'summary':x.ref} for _,x in dev_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2329e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the training examples that contained semantic errors according to Dusek et al. 2019\n",
    "# We will use these are the oracle labels for computing retrieval metrics\n",
    "train_bad_inds = [i for i, row in train_data.iterrows() if row['fixed']==1]\n",
    "\n",
    "labels = [0]*len(train_examples)\n",
    "for i in train_bad_inds:\n",
    "    labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_bad_inds = [i for i, row in dev_data.iterrows() if row['fixed']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model, article, summary, device):\n",
    "    batch = tokenizer(article, return_tensors='pt', truncation=True).to(device)\n",
    "    labels = tokenizer(summary, return_tensors='pt', truncation=True)['input_ids'].to(device)\n",
    "    decoder_input_ids = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "    batch['labels'] = labels\n",
    "    batch['decoder_input_ids'] = decoder_input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    return outputs.loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad762d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_one(model, optimizer, articles, summaries, device):\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    batch = tokenizer(articles, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    labels = tokenizer(summaries, return_tensors='pt', truncation=True, padding=True)['input_ids'].to(device)\n",
    "    decoder_input_ids = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "\n",
    "    batch['labels'] = labels\n",
    "\n",
    "    batch['decoder_input_ids'] = decoder_input_ids\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    outputs = model(**batch)\n",
    "    print(outputs.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0962d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_get_losses_after_update(articles, summaries, device, chkpt_dir='./checkpoint_9', lr=1e-5, steps=1):\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(chkpt_dir).to(device)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        batch_train_one(model, optimizer, articles, summaries, device)\n",
    "\n",
    "    train_losses_after = []\n",
    "    for ex in tqdm(train_examples):\n",
    "        train_losses_after.append(get_loss(model, ex['document'], ex['summary'], device))\n",
    "\n",
    "    return train_losses_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add50c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take gradient steps based on the original, erroneous references to get theta_orig and compute the loss for the training samples\n",
    "losses_orig = batch_get_losses_after_update(sample_mrs, sample_refs, device, chkpt_dir='./bart_base/checkpoint_0/', lr=5e-6, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take gradient steps based on the corrected references to get theta_fix and compute the loss for the training samples\n",
    "losses_fix = batch_get_losses_after_update(sample_mrs, fixed_refs, device, chkpt_dir='./bart_base/checkpoint_0/', lr=5e-6, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02befdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the loss diff for each training example\n",
    "diff = [x-y for x,y in zip(losses_orig, losses_fix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a512a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the training samples according to the loss diff\n",
    "# NOTE: Since we did loss_orig - loss_fix, the samples with the lowest scores are the most likely to be erroneous.\n",
    "#       This is because these are the training instances that have a relatively small loss under theta_orig and\n",
    "#       a relatively larger loss under theta_fix.\n",
    "inds = list(np.argsort(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the top 50 samples to ensure that our methods works as expected\n",
    "# NOTE: label=1 means that the training instance contained semantic errors according to Dusek et al. 2019\n",
    "[labels[x] for x in inds[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c902d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We can then take the top X samples and bottom X samples and distill these into an electra classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbaf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc387dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will laod the distilled electra model trained for the paper (taking top 500 and bottom 500 samples)\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/electra-large-discriminator')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./classifier/').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for example in tqdm(train_examples):\n",
    "    art = example['document']\n",
    "    summ = example['summary']\n",
    "    x = tokenizer.encode(art, summ, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
    "    logits = model(x).logits\n",
    "    scores.append(logits.softmax(dim=-1)[0][1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403966ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(labels, scores, average=\"samples\")*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "auc(fpr, tpr)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86144fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytroch_latest",
   "language": "python",
   "name": "pytroch_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
