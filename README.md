# Contrastive Error Attribution for Finetuned Language Models
This repository contains the data and code for the paper [Contrastive Error Attribution for Finetuned Language Models](https://aclanthology.org/2023.acl-long.643/)

The repository has a folder for each of the experiments in the paper -- [XSum canaries](https://github.com/fladhak/contrastive_error_attribution/tree/main/xsum_canaries), [NYT hallucinations](https://github.com/fladhak/contrastive_error_attribution/tree/main/nyt), and [E2E semantic errors](https://github.com/fladhak/contrastive_error_attribution/tree/main/e2e).

For each of these experiments, download the artifacts using the link provided in the README for each experiment, and follow the steps in the notebook to run the code.
